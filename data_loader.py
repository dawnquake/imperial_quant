import pandas as pd
import os
import ta

def load_market_data(symbol: str, year: int, interval: str, start_time: str, end_time: str, add_indicators: bool = True) -> pd.DataFrame:
    """
    åŠ è½½æœ¬åœ°æœŸè´§ä¸»åŠ›è¿ç»­æ•°æ®ï¼Œé€‚ç”¨äºä»»æ„å¹´ä»½æ–‡ä»¶å¤¹ã€‚

    å‚æ•°ï¼š
    ----------
    symbol : str
        å“ç§ä»£ç ï¼ˆå¦‚ 'AG9999.XSGE'ï¼‰
    year : int
        å¹´ä»½ï¼ˆå¦‚ 2024, 2025ï¼‰
    interval : str
        æ—¶é—´å‘¨æœŸï¼ˆ'1min', '3min' ç­‰ï¼‰
    start_time : str
        èµ·å§‹æ—¥æœŸï¼ˆ'YYYY-MM-DD'ï¼‰
    end_time : str
        ç»“æŸæ—¥æœŸï¼ˆ'YYYY-MM-DD'ï¼‰
    add_indicators : bool
        æ˜¯å¦æ·»åŠ æŠ€æœ¯æŒ‡æ ‡

    è¿”å›ï¼š
    ----------
    pd.DataFrameï¼Œindex ä¸º datetimeï¼Œå«è¡Œæƒ…å’ŒæŠ€æœ¯æŒ‡æ ‡å­—æ®µ
    """

    # åˆ¤æ–­æ–‡ä»¶å¤¹åï¼ˆ2025å¯èƒ½æ˜¯ä¸­æ–‡æ‹¬å·ï¼‰
    if year == 2025:
        folder_name = "2025ä¸»åŠ›è¿ç»­ï¼ˆ1-3æœˆï¼‰_1min"
    else:
        folder_name = f"{year}ä¸»åŠ›è¿ç»­_1min"

    # æ‹¼æ¥å®Œæ•´è·¯å¾„
    base_path = "./data/OneDrive_1_14-05-2025/qihuo_zhulilianxu_1min"
    file_path = os.path.join(base_path, folder_name, f"{symbol}_{year}_1min.csv")

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    # åŠ è½½æ•°æ®
    df = pd.read_csv(file_path, index_col=0, parse_dates=True)
    df.index.name = "timestamp"
    df = df.sort_index()
    df = df[(df.index >= start_time) & (df.index <= end_time)]


    if 'paused' in df.columns:
        df = df[df['paused'] == 0]
    df = df.drop(columns=['paused', 'factor', 'contract'], errors='ignore')

    if interval != '1min':
        df = df.resample(interval).agg({
            'open': 'first',
            'high': 'max',
            'low': 'min',
            'close': 'last',
            'volume': 'sum',
            'money': 'sum',
            'avg': 'mean',
            'high_limit': 'last',
            'low_limit': 'last',
            'pre_close': 'last',
            'open_interest': 'last'
        }).dropna()

    if add_indicators and len(df) > 50:
        df['ma_fast'] = df['close'].rolling(window=5).mean()
        df['ma_slow'] = df['close'].rolling(window=20).mean()
        df['rsi'] = ta.momentum.RSIIndicator(df['close'], window=14).rsi()
        macd = ta.trend.MACD(df['close'])
        df['macd'] = macd.macd()
        df['macd_signal'] = macd.macd_signal()
        df['macd_diff'] = df['macd'] - df['macd_signal']
        adx = ta.trend.ADXIndicator(df['high'], df['low'], df['close'])
        df['adx'] = adx.adx()
        df['di_pos'] = adx.adx_pos()
        df['di_neg'] = adx.adx_neg()
        boll = ta.volatility.BollingerBands(df['close'], window=20)
        df['boll_upper'] = boll.bollinger_hband()
        df['boll_lower'] = boll.bollinger_lband()
        df['boll_width'] = df['boll_upper'] - df['boll_lower']
        df['atr'] = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close']).average_true_range()
        df['volatility'] = df['close'].pct_change().rolling(window=10).std()
        df['volume_sma'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma']
        df['price_return'] = df['close'].pct_change()
        df['momentum_10'] = df['close'].diff(periods=10)
        df['price_vs_ma'] = df['close'] - df['ma_slow']
        df['price_vs_boll'] = df['close'] - (df['boll_upper'] + df['boll_lower']) / 2

    return df


import numpy as np

def preprocess_futures_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ¸…æ´—æœŸè´§åˆ†é’Ÿæ•°æ®ï¼Œå»é™¤å¼‚å¸¸å€¼ã€å‰è§†åå·®ã€ç¼ºå¤±å€¼ç­‰é—®é¢˜ï¼Œå¹¶æ·»åŠ åŸºç¡€è¡ç”ŸæŒ‡æ ‡ã€‚
    åŒæ—¶è¾“å‡ºæ¯ä¸€æ­¥æ£€æµ‹åˆ°çš„é—®é¢˜åŠæ‰€é‡‡å–çš„å¤„ç†æªæ–½ã€‚
    """
    print("ğŸ§¼ å¼€å§‹é¢„å¤„ç†æ•°æ®...")

    original_len = len(df)

    # 1. Remove paused rows
    if 'paused' in df.columns:
        paused_count = (df['paused'] == 1.0).sum()
        if paused_count > 0:
            print(f"âš ï¸ å‘ç° {paused_count} è¡Œäº¤æ˜“æš‚åœï¼ˆpaused == 1.0ï¼‰ï¼Œå·²å‰”é™¤ã€‚")
        df = df[df['paused'] == 0]

    # 2. Remove rows with zero volume
    zero_volume_count = (df['volume'] == 0).sum()
    if zero_volume_count > 0:
        print(f"âš ï¸ å‘ç° {zero_volume_count} è¡Œæˆäº¤é‡ä¸º 0ï¼Œå·²å‰”é™¤ã€‚")
    df = df[df['volume'] > 0]

    # 3. Drop rows with any NaNs
    nan_rows = df.isna().any(axis=1).sum()
    if nan_rows > 0:
        print(f"âš ï¸ å‘ç° {nan_rows} è¡Œå«æœ‰ç¼ºå¤±å€¼ï¼Œå·²åˆ é™¤ã€‚")
    df = df.dropna()

    # 4. Detect and clip extreme log returns
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    spike_count = (df['log_return'].abs() > 0.2).sum()
    if spike_count > 0:
        print(f"âš ï¸ å‘ç° {spike_count} è¡Œä»·æ ¼æ³¢åŠ¨è¿‡å¤§ï¼ˆlog_return è¶…è¿‡ Â±20%ï¼‰ï¼Œå·²è£å‰ªã€‚")
    df['log_return'] = df['log_return'].clip(-0.2, 0.2)

    # 5. Remove extreme rows entirely
    df = df[df['log_return'].abs() < 0.2]

    # 6. Add derived features
    df['return'] = df['close'].pct_change()
    df['momentum_10'] = df['close'].diff(10)
    df['volatility_10'] = df['return'].rolling(window=10).std()

    # 7. Volume normalization
    df['volume_sma'] = df['volume'].rolling(20).mean()
    df['volume_ratio'] = df['volume'] / (df['volume_sma'] + 1e-6)
    df['volume_ratio'] = df['volume_ratio'].clip(0, 5)

    # 8. Open interest normalization
    if 'open_interest' in df.columns:
        df['oi_change'] = df['open_interest'].diff()
        df['oi_change_norm'] = df['oi_change'] / (df['open_interest'].rolling(20).mean() + 1e-6)

    # 9. Shift to prevent lookahead bias
    shifted_cols = ['return', 'log_return', 'momentum_10', 'volatility_10', 'volume_ratio', 'oi_change_norm']
    for col in shifted_cols:
        if col in df.columns:
            df[col] = df[col].shift(1)

    # 10. Final cleanup
    final_nan_rows = df.isna().any(axis=1).sum()
    if final_nan_rows > 0:
        print(f"âš ï¸ æœ€åå¤„ç†é˜¶æ®µå‘ç° {final_nan_rows} è¡Œå› è¡ç”Ÿåˆ—åç§»äº§ç”Ÿ NaNï¼Œå·²åˆ é™¤ã€‚")
    df = df.dropna()

    print(f"âœ… é¢„å¤„ç†å®Œæˆï¼šåŸå§‹ {original_len} è¡Œ â†’ å‰©ä½™ {len(df)} è¡Œï¼ˆæ¸…æ´—æ‰ {original_len - len(df)} è¡Œï¼‰\n")

    return df


def resample_to_3min(df_1min: pd.DataFrame) -> pd.DataFrame:
    """
    å°†æœŸè´§1åˆ†é’Ÿæ•°æ®é‡é‡‡æ ·ä¸º3åˆ†é’Ÿæ•°æ®ã€‚

    OHLC ä½¿ç”¨æ ‡å‡†é‡‘èèšåˆæ–¹å¼ï¼š
    - open: ç¬¬ä¸€ä¸ªå€¼
    - high: æœ€å¤§å€¼
    - low: æœ€å°å€¼
    - close: æœ€åä¸€ä¸ªå€¼
    æˆäº¤é‡ã€æˆäº¤é¢åšåŠ å’Œï¼ŒæŒä»“é‡å–æœ€åå€¼

    å‚æ•°ï¼š
    ----------
    df_1min : pd.DataFrame
        å¿…é¡»åŒ…å« 'open', 'high', 'low', 'close', 'volume', 'money', 'open_interest'

    è¿”å›ï¼š
    ----------
    df_3min : pd.DataFrame
    """
    if not isinstance(df_1min.index, pd.DatetimeIndex):
        raise ValueError("DataFrame must have a DatetimeIndex.")

    df_3min = df_1min.resample("3T").agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum',
        'money': 'sum',
        'avg': 'mean' if 'avg' in df_1min.columns else 'mean',
        'high_limit': 'last',
        'low_limit': 'last',
        'pre_close': 'last',
        'open_interest': 'last'
    })

    df_3min = df_3min.dropna(subset=['open', 'close'])  # drop incomplete intervals

    return df_3min


import matplotlib.pyplot as plt
import numpy as np

def visualize_market_data(data_dict: dict, max_symbols: int = 6, save_path: str = "./data/market_data_summary.pdf"):
    """
    å¯è§†åŒ–å·²åŠ è½½çš„æœŸè´§æ•°æ®ï¼Œå±•ç¤ºä»·æ ¼ä¸æˆäº¤é‡ï¼Œå¹¶ä¿å­˜ä¸º PDFã€‚

    å‚æ•°ï¼š
    ----------
    data_dict : dict
        {symbol: DataFrame} ç»“æ„
    max_symbols : int
        æœ€å¤šå±•ç¤ºå¤šå°‘ä¸ªå“ç§ï¼ˆé¿å…å›¾å¤ªå¤šï¼‰
    save_path : str
        PDF ä¿å­˜è·¯å¾„
    """
    symbols = list(data_dict.keys())[:max_symbols]
    num_plots = len(symbols)

    if num_plots == 0:
        print("âš ï¸ æ²¡æœ‰å¯è§†åŒ–çš„æ•°æ®")
        return

    fig, axes = plt.subplots(num_plots, 2, figsize=(12, 4 * num_plots), sharex=False)
    if num_plots == 1:
        axes = [axes]  # ensure iterable if only 1 row
    elif isinstance(axes[0], plt.Axes):
        axes = [axes]  # force to list of pairs

    for i, symbol in enumerate(symbols):
        df = data_dict[symbol]
        if df.empty:
            continue

        # âœ… Convert to numpy arrays to avoid pandas indexing issues
        time = np.array(df.index)
        price = np.array(df['close'])
        volume = np.array(df['volume'])

        ax_price = axes[i][0]
        ax_volume = axes[i][1]

        ax_price.plot(time, price, label='Close Price', color='blue')
        ax_price.set_title(f"{symbol} - Close Price")
        ax_price.set_ylabel("Price")
        ax_price.grid(True)

        ax_volume.bar(time, volume, width=0.01, color='gray')
        ax_volume.set_title(f"{symbol} - Volume")
        ax_volume.set_ylabel("Volume")
        ax_volume.grid(True)

    plt.tight_layout()
    plt.savefig(save_path)
    print(f"\nğŸ“„ å›¾è¡¨å·²ä¿å­˜ä¸ºï¼š{save_path}")
    plt.close()



# ========== æ‰¹é‡æµ‹è¯•ä»£ç ï¼ˆä»…åœ¨ç›´æ¥è¿è¡Œæ—¶æ‰§è¡Œ /usr/bin/python3.10 data_loader.pyï¼‰ ==========
if __name__ == "__main__":
    base_dir = "./data/OneDrive_1_14-05-2025/qihuo_zhulilianxu_1min"

    # ğŸ”§ Set your desired year range here
    start_year = 2024
    end_year = 2025

    def iterate_all_symbols():
        for year_folder in sorted(os.listdir(base_dir)):
            folder_path = os.path.join(base_dir, year_folder)
            if not os.path.isdir(folder_path):
                continue
            try:
                year = int(year_folder[:4])  # e.g., '2024ä¸»åŠ›è¿ç»­_1min'
            except ValueError:
                continue  # skip invalid folder names

            # âœ… Filter only within the selected year range
            if year < start_year or year > end_year:
                continue

            for filename in os.listdir(folder_path):
                if filename.endswith(".csv"):
                    symbol = filename.replace(f"_{year}_1min.csv", "")
                    yield symbol, year

    print(f"ğŸš€ å¼€å§‹åŠ è½½æœŸè´§æ•°æ®ï¼ˆ{start_year}â€“{end_year}ï¼‰å¹´åŒºé—´ï¼š\n")
    success_count = 0
    fail_count = 0
    
    loaded_data = {}
    for symbol, year in iterate_all_symbols():
        try:
            df = load_market_data(
                symbol=symbol,
                year=year,
                interval="3min",
                start_time=f"{year}-01-01",
                end_time=f"{year}-12-31",
                add_indicators=False
            )
            df = preprocess_futures_data(df)
            df = resample_to_3min(df) # from 1 min to 3 min
            
            print(f"âœ… {symbol} ({year}) åŠ è½½æˆåŠŸï¼Œå…± {len(df)} è¡Œ")
            if not df.empty:
                loaded_data[f"{symbol}_{year}"] = df
            success_count += 1
        except Exception as e:
            print(f"âŒ {symbol} ({year}) åŠ è½½å¤±è´¥ï¼š{e}")
            fail_count += 1
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {success_count} ä¸ªæ–‡ä»¶ï¼ŒâŒ å¤±è´¥ {fail_count} ä¸ªæ–‡ä»¶ã€‚")

    # æœ€ç»ˆå¯è§†åŒ–ï¼ˆæœ€å¤šå±•ç¤ºå‰6ä¸ªå“ç§ï¼‰
    visualize_market_data(loaded_data)


