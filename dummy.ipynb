{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from ib_async import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_nums = {\n",
    "    \"trend\" : 1,\n",
    "    \"range\" : 0,\n",
    "}\n",
    "\n",
    "trend_range_cutoff = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantReqHistoricalData(secType: str, symbol: str, endDateTime: str, durationStr: str, barSizeSetting: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------\n",
    "    secType: str\n",
    "        Type of security\n",
    "        'STK' = Stock (or ETF)\n",
    "        'OPT' = Option\n",
    "        'FUT' = Future\n",
    "        'IND' = Index\n",
    "        'FOP' = Futures option\n",
    "        'CASH' = Forex pair\n",
    "        'CFD' = CFD\n",
    "        'BAG' = Combo\n",
    "        'WAR' = Warrant\n",
    "        'BOND' = Bond\n",
    "        'CMDTY' = Commodity\n",
    "    symbol: str\n",
    "        The contract (or its underlying) symbol\n",
    "    endDateTime: str\n",
    "        Can be set to '' to indicate the current time, or it can be given as a datetime.date or datetime.datetime, or it can be given as a string in 'yyyyMMdd HH:mm:ss' format\n",
    "    durationStr: str\n",
    "        How far back from the endDateTime to grab data\n",
    "        Accepts changes to the number\n",
    "        '60 S', '30 D', '13 W', '6 M', '10 Y'.\n",
    "    barSizeSetting: str\n",
    "        Must be one of: '1 secs', '5 secs', '10 secs' 15 secs', '30 secs', '1 min', '2 mins', '3 mins', '5 mins', '10 mins', '15 mins', '20 mins', '30 mins', '1 hour', '2 hours',\n",
    "        '3 hours', '4 hours', '8 hours', '1 day', '1 week', '1 month'.\n",
    "    \"\"\"\n",
    "\n",
    "    volume_bars, volatility_bars, all_bars = None, None, None\n",
    "\n",
    "    try:\n",
    "\n",
    "        contract = Contract(secType=secType, symbol=symbol, exchange='SMART', currency='USD')\n",
    "        volume_bars = ib.reqHistoricalData(\n",
    "            contract, endDateTime=endDateTime, durationStr=durationStr,\n",
    "            barSizeSetting=barSizeSetting, whatToShow='TRADES', useRTH=True, timeout=0)\n",
    "\n",
    "        # Convert to pandas dataframe\n",
    "        volume_bars = util.df(volume_bars)\n",
    "        volume_bars.sort_values(by=['date'], ascending=False, inplace=True)\n",
    "        volume_bars.columns = [\"date\" if col == \"date\" else \"volume_\" + col for col in volume_bars.columns]\n",
    "\n",
    "        \"\"\"\n",
    "        volatility_bars = ib.reqHistoricalData(\n",
    "            contract, endDateTime=endDateTime, durationStr=durationStr,\n",
    "            barSizeSetting=barSizeSetting, whatToShow='HISTORICAL_VOLATILITY', useRTH=True, timeout=0)\n",
    "\n",
    "        volatility_bars = util.df(volatility_bars)\n",
    "        volatility_bars.sort_values(by=['date'], ascending=False, inplace=True)\n",
    "        volatility_bars.columns = [\"date\" if col == \"date\" else \"volatility_\" + col for col in volatility_bars.columns]\n",
    "        \"\"\"\n",
    "\n",
    "        # all_bars = pd.merge(volume_bars, volatility_bars, on=\"date\", how=\"inner\")\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(e)\n",
    "\n",
    "    finally:\n",
    "\n",
    "        # Make sure to disconnect the client once finished with client work\n",
    "        ib.disconnect()\n",
    "        time.sleep(5)\n",
    "\n",
    "    return volume_bars\n",
    "\n",
    "\n",
    "def extract_session_info(session_bars: pd.DataFrame, threshold: float = trend_range_cutoff):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a session_bars find out if the session is a range session or trend sessio\n",
    "    Also extract useful information from the session\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_bars: pd.Dataframe\n",
    "        the session to investigate\n",
    "    threshold: float\n",
    "        threshold for deciding if trend or range\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    session_open_price: float\n",
    "        Price at the opening of the session\n",
    "    session_close_price: float\n",
    "        Price at the close of the session\n",
    "    session_max_price: float\n",
    "        Maximum price during the session\n",
    "    session_min_price: float\n",
    "        Minimum price during the session\n",
    "    session_volume_total: float\n",
    "        Total number of units traded during the session\n",
    "    session_nr_trades: float\n",
    "        Total number of trades during the session\n",
    "    session_volume_per_trade\n",
    "        Average number of shares per trade in the session\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    volatility = session_bars.volume_close.pct_change().std() * (len(session_bars) ** 0.5)\n",
    "    trend_score = (session_bars.volume_close.max() - session_bars.volume_close.min()) / (volatility * session_bars.volume_close.iloc[0] + 1e-6)\n",
    "    # label = 'trend' if abs(trend_score) > threshold else 'range'\n",
    "    label = 1 if abs(trend_score) > threshold else 0\n",
    "    \n",
    "    session_open_price = session_bars.loc[session_bars['date'].idxmin(), \"volume_open\"]\n",
    "    session_close_price = session_bars.loc[session_bars['date'].idxmin(), \"volume_close\"]\n",
    "    session_max_price = session_bars[\"volume_high\"].max()\n",
    "    session_min_price = session_bars[\"volume_low\"].max()\n",
    "    session_volume_total = session_bars[\"volume_volume\"].sum()\n",
    "    session_nr_trades =   session_bars[\"volume_barCount\"].sum()\n",
    "    session_volume_per_trade = session_bars[\"volume_volume\"].sum() / session_bars[\"volume_barCount\"].sum()\n",
    "    session_info = {\n",
    "        \"label\": label,\n",
    "        \"session_open_price\": session_open_price,\n",
    "        \"session_close_price\": session_close_price,\n",
    "        \"session_max_price\": session_max_price,\n",
    "        \"session_min_price\": session_min_price,\n",
    "        \"session_volume_total\": session_volume_total,\n",
    "        \"session_nr_trades\": session_nr_trades,\n",
    "        \"session_volume_per_trade\": session_volume_per_trade,\n",
    "    }\n",
    "\n",
    "    return session_info \n",
    "\n",
    "def volume_bars_to_labelled_session(volume_bars: pd.DataFrame):\n",
    "\n",
    "    \"\"\"\n",
    "    Convert volume_bars to labelled_sessions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    volume_bars: pd.DataFrame\n",
    "        dataframe of volume bars\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    labelled_session: dict\n",
    "        {date: {'session_df': session_df, 'session_label': label_session(session_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    volume_bars_copy = copy.deepcopy(volume_bars)\n",
    "    volume_bars_copy['date_days'] = volume_bars_copy['date'].astype(str).str.split(' ').str[0]\n",
    "    volume_bars_groupby_date = {key: values for key, values in volume_bars_copy.groupby(\"date_days\")}\n",
    "\n",
    "    \n",
    "    labelled_sessions = {date: {'session_df': session_df,\n",
    "                                'session_info': extract_session_info(session_df),\n",
    "                                }\n",
    "\n",
    "                         \n",
    "                         for date, session_df in volume_bars_groupby_date.items()}\n",
    "\n",
    "    return labelled_sessions\n",
    "\n",
    "\n",
    "\n",
    "def create_bracket_order(secType: str, symbol: str, action: str, quantity: int, entry_price: float, take_profit_price: float, stop_loss_price: float):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------\n",
    "    secType: str\n",
    "        Type of security\n",
    "        'STK' = Stock (or ETF)\n",
    "        'OPT' = Option\n",
    "        'FUT' = Future\n",
    "        'IND' = Index\n",
    "        'FOP' = Futures option\n",
    "        'CASH' = Forex pair\n",
    "        'CFD' = CFD\n",
    "        'BAG' = Combo\n",
    "        'WAR' = Warrant\n",
    "        'BOND' = Bond\n",
    "        'CMDTY' = Commodity\n",
    "    symbol: str\n",
    "        The contract (or its underlying) symbol\n",
    "    action: str\n",
    "        BUY or SELL\n",
    "    quantity: int\n",
    "        The number to buy\n",
    "    entry_price: float\n",
    "        Entry price, set below market price to immediately execute the order at next available time\n",
    "    take_profit_price: float\n",
    "        Take Profit\n",
    "    stop_loss_price: float\n",
    "        Stop loss\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    contract = Contract(secType=secType, symbol=symbol, exchange='SMART', currency='USD')\n",
    "    \n",
    "    # Define order parameters\n",
    "    quantity = 10\n",
    "    entry_price = 150  # Your entry price\n",
    "    take_profit_price = 160  # Target price\n",
    "    stop_loss_price = 145  # Stop loss price\n",
    "    \n",
    "    # Create the bracket order\n",
    "    bracket = ib.bracketOrder(\n",
    "        action=action,\n",
    "        quantity=quantity,\n",
    "        limitPrice=entry_price,\n",
    "        takeProfitPrice=take_profit_price,\n",
    "        stopLossPrice=stop_loss_price\n",
    "    )\n",
    "    \n",
    "    # Place the bracket order\n",
    "    for order in bracket:\n",
    "        ib.placeOrder(contract, order)\n",
    "    \n",
    "    print(\"Bracket order placed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.startLoop()  # uncomment this line when in a notebook\n",
    "\n",
    "ib = IB()\n",
    "ib.connect('127.0.0.1', 7496, clientId=2)\n",
    "ib.reqMarketDataType(1)  # Use free, delayed, fr ozen data\n",
    "volume_bars = quantReqHistoricalData(secType = \"STK\", symbol = \"TSLA\", endDateTime = \"\", durationStr = \"10 Y\", barSizeSetting = \"3 mins\")\n",
    "\n",
    "volume_bars.to_csv(\"TSLA_10Y3mins_RTH.csv\", index=False)\n",
    "\n",
    "ib.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>session_open_price</th>\n",
       "      <th>session_close_price</th>\n",
       "      <th>session_max_price</th>\n",
       "      <th>session_min_price</th>\n",
       "      <th>session_volume_total</th>\n",
       "      <th>session_nr_trades</th>\n",
       "      <th>session_volume_per_trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>1</td>\n",
       "      <td>32.57</td>\n",
       "      <td>32.58</td>\n",
       "      <td>33.07</td>\n",
       "      <td>33.04</td>\n",
       "      <td>153466400.0</td>\n",
       "      <td>184026</td>\n",
       "      <td>833.938683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>32.97</td>\n",
       "      <td>32.95</td>\n",
       "      <td>32.99</td>\n",
       "      <td>32.96</td>\n",
       "      <td>100008000.0</td>\n",
       "      <td>109680</td>\n",
       "      <td>911.816193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-29</td>\n",
       "      <td>1</td>\n",
       "      <td>32.81</td>\n",
       "      <td>32.82</td>\n",
       "      <td>32.86</td>\n",
       "      <td>32.81</td>\n",
       "      <td>149351200.0</td>\n",
       "      <td>163941</td>\n",
       "      <td>911.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32.84</td>\n",
       "      <td>32.79</td>\n",
       "      <td>32.85</td>\n",
       "      <td>32.74</td>\n",
       "      <td>110002576.0</td>\n",
       "      <td>124031</td>\n",
       "      <td>886.895824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>32.47</td>\n",
       "      <td>32.56</td>\n",
       "      <td>32.67</td>\n",
       "      <td>32.64</td>\n",
       "      <td>121245600.0</td>\n",
       "      <td>125181</td>\n",
       "      <td>968.562322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>1</td>\n",
       "      <td>207.78</td>\n",
       "      <td>206.34</td>\n",
       "      <td>209.48</td>\n",
       "      <td>209.23</td>\n",
       "      <td>26756989.0</td>\n",
       "      <td>147381</td>\n",
       "      <td>181.549786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>207.67</td>\n",
       "      <td>207.12</td>\n",
       "      <td>208.47</td>\n",
       "      <td>208.14</td>\n",
       "      <td>23605310.0</td>\n",
       "      <td>126482</td>\n",
       "      <td>186.629797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>1</td>\n",
       "      <td>205.17</td>\n",
       "      <td>204.84</td>\n",
       "      <td>207.04</td>\n",
       "      <td>206.74</td>\n",
       "      <td>37401976.0</td>\n",
       "      <td>210840</td>\n",
       "      <td>177.395067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>1</td>\n",
       "      <td>200.71</td>\n",
       "      <td>201.05</td>\n",
       "      <td>202.75</td>\n",
       "      <td>202.45</td>\n",
       "      <td>29211675.0</td>\n",
       "      <td>156962</td>\n",
       "      <td>186.106669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>0</td>\n",
       "      <td>193.67</td>\n",
       "      <td>195.83</td>\n",
       "      <td>197.70</td>\n",
       "      <td>197.00</td>\n",
       "      <td>43987512.0</td>\n",
       "      <td>221412</td>\n",
       "      <td>198.668148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  label  session_open_price  session_close_price  \\\n",
       "0     2015-05-27      1               32.57                32.58   \n",
       "1     2015-05-28      0               32.97                32.95   \n",
       "2     2015-05-29      1               32.81                32.82   \n",
       "3     2015-06-01      0               32.84                32.79   \n",
       "4     2015-06-02      1               32.47                32.56   \n",
       "...          ...    ...                 ...                  ...   \n",
       "2510  2025-05-19      1              207.78               206.34   \n",
       "2511  2025-05-20      1              207.67               207.12   \n",
       "2512  2025-05-21      1              205.17               204.84   \n",
       "2513  2025-05-22      1              200.71               201.05   \n",
       "2514  2025-05-23      0              193.67               195.83   \n",
       "\n",
       "      session_max_price  session_min_price  session_volume_total  \\\n",
       "0                 33.07              33.04           153466400.0   \n",
       "1                 32.99              32.96           100008000.0   \n",
       "2                 32.86              32.81           149351200.0   \n",
       "3                 32.85              32.74           110002576.0   \n",
       "4                 32.67              32.64           121245600.0   \n",
       "...                 ...                ...                   ...   \n",
       "2510             209.48             209.23            26756989.0   \n",
       "2511             208.47             208.14            23605310.0   \n",
       "2512             207.04             206.74            37401976.0   \n",
       "2513             202.75             202.45            29211675.0   \n",
       "2514             197.70             197.00            43987512.0   \n",
       "\n",
       "      session_nr_trades  session_volume_per_trade  \n",
       "0                184026                833.938683  \n",
       "1                109680                911.816193  \n",
       "2                163941                911.005789  \n",
       "3                124031                886.895824  \n",
       "4                125181                968.562322  \n",
       "...                 ...                       ...  \n",
       "2510             147381                181.549786  \n",
       "2511             126482                186.629797  \n",
       "2512             210840                177.395067  \n",
       "2513             156962                186.106669  \n",
       "2514             221412                198.668148  \n",
       "\n",
       "[2515 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "volume_bars = pd.read_csv(os.path.join(\"stocks_past_data\",\"AAPL_10Y3mins_RTH.csv\"))\n",
    "labelled_sessions = volume_bars_to_labelled_session(volume_bars)\n",
    "\n",
    "newdf = pd.DataFrame([{'date': date, **values['session_info']} for date, values in labelled_sessions.items()])\n",
    "\n",
    "display(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123 392\n"
     ]
    }
   ],
   "source": [
    "print(len(newdf[newdf[\"label\"] == 1]), len(newdf[newdf[\"label\"] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dawnquake\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8421 - loss: 0.5475 - val_accuracy: 0.8563 - val_loss: 0.4278\n",
      "Epoch 2/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.4529 - val_accuracy: 0.8563 - val_loss: 0.4156\n",
      "Epoch 3/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8304 - loss: 0.4569 - val_accuracy: 0.8563 - val_loss: 0.4120\n",
      "Epoch 4/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.4637 - val_accuracy: 0.8563 - val_loss: 0.4463\n",
      "Epoch 5/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.4313 - val_accuracy: 0.8563 - val_loss: 0.4218\n",
      "Epoch 6/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.4243 - val_accuracy: 0.8563 - val_loss: 0.4245\n",
      "Epoch 7/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.4442 - val_accuracy: 0.8563 - val_loss: 0.4139\n",
      "Epoch 8/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.4396 - val_accuracy: 0.8563 - val_loss: 0.4220\n",
      "Epoch 9/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.4055 - val_accuracy: 0.8563 - val_loss: 0.4109\n",
      "Epoch 10/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4475 - val_accuracy: 0.8563 - val_loss: 0.4277\n",
      "Epoch 11/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.4097 - val_accuracy: 0.8563 - val_loss: 0.4153\n",
      "Epoch 12/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.4394 - val_accuracy: 0.8563 - val_loss: 0.4115\n",
      "Epoch 13/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.4091 - val_accuracy: 0.8563 - val_loss: 0.4143\n",
      "Epoch 14/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.4358 - val_accuracy: 0.8563 - val_loss: 0.4113\n",
      "Epoch 15/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 0.4454 - val_accuracy: 0.8563 - val_loss: 0.4250\n",
      "Epoch 16/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8299 - loss: 0.4521 - val_accuracy: 0.8563 - val_loss: 0.4172\n",
      "Epoch 17/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.4401 - val_accuracy: 0.8563 - val_loss: 0.4122\n",
      "Epoch 18/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.4464 - val_accuracy: 0.8563 - val_loss: 0.4112\n",
      "Epoch 19/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.4361 - val_accuracy: 0.8563 - val_loss: 0.4132\n",
      "Epoch 20/20\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.4230 - val_accuracy: 0.8563 - val_loss: 0.4127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Predict the next day\\'s label\\nnext_day_features = np.expand_dims(df.iloc[-SEQ_LENGTH:][features].values, axis=0)\\npredicted_label = model.predict(next_day_features)\\n\\n# Convert probability to binary label\\npredicted_label = (predicted_label > 0.5).astype(int)\\nprint(f\"Predicted label for the next day: {predicted_label[0][0]}\")\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_sequences(data, features, target, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length][features].values)\n",
    "        y.append(data.iloc[i+seq_length][target])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_prediction_model(df: pd.DataFrame, target: str = label):\n",
    "\n",
    "    \"\"\"\n",
    "    # Predict the next day's label\n",
    "    next_day_features = np.expand_dims(df.iloc[-SEQ_LENGTH:][features].values, axis=0)\n",
    "    predicted_label = model.predict(next_day_features)\n",
    "    \n",
    "    # Convert probability to binary label\n",
    "    predicted_label = (predicted_label > 0.5).astype(int)\n",
    "    print(f\"Predicted label for the next day: {predicted_label[0][0]}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_model = None\n",
    "    \n",
    "    df = copy.deepcopy(df)\n",
    "    features = [i for i in list(newdf.columns) if i not in [\"label\", \"date\"]]\n",
    "\n",
    "    # Feature Engineering\n",
    "    scaler = MinMaxScaler()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "    # Past 29 sessions in CN, given 3 sessions per day, means 10 sessions in US\n",
    "    SEQ_LENGTH = 10  \n",
    "    X, y = create_sequences(df, features, target, SEQ_LENGTH)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    split = int(0.8 * len(X))\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "    \n",
    "    # Define LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation=\"relu\", return_sequences=True, input_shape=(SEQ_LENGTH, len(features))),\n",
    "        LSTM(50, activation=\"relu\"),\n",
    "        Dense(25, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))\n",
    "    \n",
    "    return model\n",
    "\n",
    "prediction_model = create_prediction_model(newdf)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
